Help on class StringLookup in module keras.layers.preprocessing.string_lookup:
class StringLookup(keras.layers.preprocessing.index_lookup.IndexLookup)
|  StringLookup(max_tokens=None, num_oov_indices=1, mask_token=None, oov_token='[UNK]', vocabulary=None, idf_weights=None, encoding=None, invert=False, output_mode='int', sparse=False, pad_to_max_tokens=False, **kwargs)
|
|  A preprocessing layer which maps string features to integer indices.
|
|  This layer translates a set of arbitrary strings into integer output via a
|  table-based vocabulary lookup. This layer will perform no splitting or
|  transformation of input strings. For a layer than can split and tokenize
|  natural language, see the `TextVectorization` layer.
|
|  The vocabulary for the layer must be either supplied on construction or
|  learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
|  determine the frequency of individual strings tokens, and create a
|  vocabulary from them. If the vocabulary is capped in size, the most frequent
|  tokens will be used to create the vocabulary and all others will be treated
|  as out-of-vocabulary (OOV).
|
|  There are two possible output modes for the layer.
|  When `output_mode` is `"int"`,
|  input strings are converted to their index in the vocabulary (an integer).
|  When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`, input strings
|  are encoded into an array where each dimension corresponds to an element in
|  the vocabulary.
|
|  The vocabulary can optionally contain a mask token as well as an OOV token
|  (which can optionally occupy multiple indices in the vocabulary, as set
|  by `num_oov_indices`).
|  The position of these tokens in the vocabulary is fixed. When `output_mode`
|  is `"int"`, the vocabulary will begin with the mask token (if set), followed
|  by OOV indices, followed by the rest of the vocabulary. When `output_mode`
|  is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will begin with
|  OOV indices and instances of the mask token will be dropped.
|
|  For an overview and full list of preprocessing layers, see the preprocessing
|  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
|
|  Args:
|    max_tokens: Maximum size of the vocabulary for this layer. This should
|      only be specified when adapting the vocabulary or when setting
|      `pad_to_max_tokens=True`. If None, there is no cap on the size of the
|      vocabulary. Note that this size includes the OOV and mask tokens.
|      Defaults to None.
|    num_oov_indices: The number of out-of-vocabulary tokens to use. If this
|      value is more than 1, OOV inputs are hashed to determine their OOV
|      value. If this value is 0, OOV inputs will cause an error when calling
|      the layer.  Defaults to 1.
|    mask_token: A token that represents masked inputs. When `output_mode` is
|      `"int"`, the token is included in vocabulary and mapped to index 0. In
|      other output modes, the token will not appear in the vocabulary and
|      instances of the mask token in the input will be dropped. If set to
|      None, no mask term will be added. Defaults to `None`.
|    oov_token: Only used when `invert` is True. The token to return for OOV
|      indices. Defaults to `"[UNK]"`.
|    vocabulary: Optional. Either an array of strings or a string path to a
|      text file. If passing an array, can pass a tuple, list, 1D numpy array,
|      or 1D tensor containing the string vocbulary terms. If passing a file
|      path, the file should contain one line per term in the vocabulary. If
|      this argument is set, there is no need to `adapt()` the layer.
|    idf_weights: Only valid when `output_mode` is `"tf_idf"`. A tuple, list,
|      1D numpy array, or 1D tensor or the same length as the vocabulary,
|      containing the floating point inverse document frequency weights, which
|      will be multiplied by per sample term counts for the final `tf_idf`
|      weight. If the `vocabulary` argument is set, and `output_mode` is
|      `"tf_idf"`, this argument must be supplied.
|    invert: Only valid when `output_mode` is `"int"`. If True, this layer will
|      map indices to vocabulary items instead of mapping vocabulary items to
|      indices. Default to False.
|    output_mode: Specification for the output of the layer. Defaults to
|      `"int"`.  Values can be `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`,
|      or `"tf_idf"` configuring the layer as follows:
|        - `"int"`: Return the raw integer indices of the input tokens.
|        - `"one_hot"`: Encodes each individual element in the input into an
|          array the same size as the vocabulary, containing a 1 at the element
|          index. If the last dimension is size 1, will encode on that
|          dimension. If the last dimension is not size 1, will append a new
|          dimension for the encoded output.
|        - `"multi_hot"`: Encodes each sample in the input into a single array
|          the same size as the vocabulary, containing a 1 for each vocabulary
|          term present in the sample. Treats the last dimension as the sample
|          dimension, if input shape is (..., sample_length), output shape will
|          be (..., num_tokens).
|        - `"count"`: As `"multi_hot"`, but the int array contains a count of
|          the number of times the token at that index appeared in the sample.
|        - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is applied to
|          find the value in each token slot.
|      For `"int"` output, any shape of input and output is supported. For all
|      other output modes, currently only output up to rank 2 is supported.
|    pad_to_max_tokens: Only applicable when `output_mode` is `"multi_hot"`,
|      `"count"`, or `"tf_idf"`. If True, the output will have its feature axis
|      padded to `max_tokens` even if the number of unique tokens in the
|      vocabulary is less than max_tokens, resulting in a tensor of shape
|      [batch_size, max_tokens] regardless of vocabulary size. Defaults to
|      False.
|    sparse: Boolean. Only applicable when `output_mode` is `"multi_hot"`,
|      `"count"`, or `"tf_idf"`. If True, returns a `SparseTensor` instead of a
|      dense `Tensor`. Defaults to False.
|
|  Examples:
|
|  **Creating a lookup layer with a known vocabulary**
|
|  This example creates a lookup layer with a pre-existing vocabulary.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
|  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
|  array([[1, 3, 4],
|         [4, 0, 2]])>
|
|  **Creating a lookup layer with an adapted vocabulary**
|
|  This example creates a lookup layer and generates the vocabulary by
|  analyzing the dataset.
|
|  >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
|  >>> layer = tf.keras.layers.StringLookup()
|  >>> layer.adapt(data)
|  >>> layer.get_vocabulary()
|  ['[UNK]', 'd', 'z', 'c', 'b', 'a']
|
|  Note that the OOV token `"[UNK]"` has been added to the vocabulary.
|  The remaining tokens are sorted by frequency
|  (`"d"`, which has 2 occurrences, is first) then by inverse sort order.
|
|  >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
|  >>> layer = tf.keras.layers.StringLookup()
|  >>> layer.adapt(data)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
|  array([[5, 3, 1],
|         [1, 2, 4]])>
|
|  **Lookups with multiple OOV indices**
|
|  This example demonstrates how to use a lookup layer with multiple OOV
|  indices.  When a layer is created with more than one OOV index, any OOV
|  values are hashed into the number of OOV buckets, distributing OOV values in
|  a deterministic fashion across the set.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([["a", "c", "d"], ["m", "z", "b"]])
|  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab,
|  ...                                      num_oov_indices=2)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
|  array([[2, 4, 5],
|         [0, 1, 3]])>
|
|  Note that the output for OOV value 'm' is 0, while the output for OOV value
|  'z' is 1. The in-vocab terms have their output index increased by 1 from
|  earlier examples (a maps to 2, etc) in order to make space for the extra OOV
|  value.
|
|  **One-hot output**
|
|  Configure the layer with `output_mode='one_hot'`. Note that the first
|  `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant(["a", "b", "c", "d", "z"])
|  >>> layer = tf.keras.layers.StringLookup(
|  ...     vocabulary=vocab, output_mode='one_hot')
|  >>> layer(data)
|  <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
|    array([[0., 1., 0., 0., 0.],
|           [0., 0., 1., 0., 0.],
|           [0., 0., 0., 1., 0.],
|           [0., 0., 0., 0., 1.],
|           [1., 0., 0., 0., 0.]], dtype=float32)>
|
|  **Multi-hot output**
|
|  Configure the layer with `output_mode='multi_hot'`. Note that the first
|  `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
|  >>> layer = tf.keras.layers.StringLookup(
|  ...     vocabulary=vocab, output_mode='multi_hot')
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
|    array([[0., 1., 0., 1., 1.],
|           [1., 0., 1., 0., 1.]], dtype=float32)>
|
|  **Token count output**
|
|  Configure the layer with `output_mode='count'`. As with multi_hot output,
|  the first `num_oov_indices` dimensions in the output represent OOV values.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
|  >>> layer = tf.keras.layers.StringLookup(
|  ...     vocabulary=vocab, output_mode='count')
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
|    array([[0., 1., 0., 1., 2.],
|           [2., 0., 1., 0., 1.]], dtype=float32)>
|
|  **TF-IDF output**
|
|  Configure the layer with `output_mode="tf_idf"`. As with multi_hot output,
|  the first `num_oov_indices` dimensions in the output represent OOV values.
|
|  Each token bin will output `token_count * idf_weight`, where the idf weights
|  are the inverse document frequency weights per token. These should be
|  provided along with the vocabulary. Note that the `idf_weight` for OOV
|  values will default to the average of all idf weights passed in.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> idf_weights = [0.25, 0.75, 0.6, 0.4]
|  >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
|  >>> layer = tf.keras.layers.StringLookup(output_mode="tf_idf")
|  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
|    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
|           [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
|
|  To specify the idf weights for oov values, you will need to pass the entire
|  vocabularly including the leading oov token.
|
|  >>> vocab = ["[UNK]", "a", "b", "c", "d"]
|  >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
|  >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
|  >>> layer = tf.keras.layers.StringLookup(output_mode="tf_idf")
|  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
|    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
|           [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
|
|  When adapting the layer in `"tf_idf"` mode, each input sample will be
|  considered a document, and IDF weight per token will be calculated as
|  `log(1 + num_documents / (1 + token_document_count))`.
|
|  **Inverse lookup**
|
|  This example demonstrates how to map indices to strings using this layer.
|  (You can also use `adapt()` with `inverse=True`, but for simplicity we'll
|  pass the vocab in this example.)
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([[1, 3, 4], [4, 0, 2]])
|  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)
|  >>> layer(data)
|  <tf.Tensor: shape=(2, 3), dtype=string, numpy=
|  array([[b'a', b'c', b'd'],
|         [b'd', b'[UNK]', b'b']], dtype=object)>
|
|  Note that the first index correspond to the oov token by default.
|
|
|  **Forward and inverse lookup pairs**
|
|  This example demonstrates how to use the vocabulary of a standard lookup
|  layer to create an inverse lookup layer.
|
|  >>> vocab = ["a", "b", "c", "d"]
|  >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
|  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)
|  >>> i_layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)
|  >>> int_data = layer(data)
|  >>> i_layer(int_data)
|  <tf.Tensor: shape=(2, 3), dtype=string, numpy=
|  array([[b'a', b'c', b'd'],
|         [b'd', b'[UNK]', b'b']], dtype=object)>
|
|  In this example, the input value `"z"` resulted in an output of `"[UNK]"`,
|  since 1000 was not in the vocabulary - it got represented as an OOV, and all
|  OOV values are returned as `"[UNK]"` in the inverse layer. Also, note that
|  for the inverse to work, you must have already set the forward layer
|  vocabulary either directly or via `adapt()` before calling
|  `get_vocabulary()`.
|
|  Method resolution order:
|      StringLookup
|      keras.layers.preprocessing.index_lookup.IndexLookup
|      keras.engine.base_preprocessing_layer.PreprocessingLayer
|      keras.engine.base_layer.Layer
|      tensorflow.python.module.module.Module
|      tensorflow.python.trackable.autotrackable.AutoTrackable
|      tensorflow.python.trackable.base.Trackable
|      keras.utils.version_utils.LayerVersionSelector
|      builtins.object
|
|  Methods defined here:
|
|  __init__(self, max_tokens=None, num_oov_indices=1, mask_token=None, oov_token='[UNK]', vocabulary=None, idf_weights=None, encoding=None, invert=False, output_mode='int', sparse=False, pad_to_max_tokens=False, **kwargs)
|
|  adapt(self, data, batch_size=None, steps=None)
|      Computes a vocabulary of string terms from tokens in a dataset.
|
|      Calling `adapt()` on a `StringLookup` layer is an alternative to passing
|      in a precomputed vocabulary on construction via the `vocabulary`
|      argument. A `StringLookup` layer should always be either adapted over a
|      dataset or supplied with a vocabulary.
|
|      During `adapt()`, the layer will build a vocabulary of all string tokens
|      seen in the dataset, sorted by occurrence count, with ties broken by
|      sort order of the tokens (high to low). At the end of `adapt()`, if
|      `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`
|      size. For example, adapting a layer with `max_tokens=1000` will compute
|      the 1000 most frequent tokens occurring in the input dataset. If
|      `output_mode='tf-idf'`, `adapt()` will also learn the document
|      frequencies of each token in the input dataset.
|
|      In order to make `StringLookup` efficient in any distribution context,
|      the vocabulary is kept static with respect to any compiled `tf.Graph`s
|      that call the layer. As a consequence, if the layer is adapted a second
|      time, any models using the layer should be re-compiled. For more
|      information see
|      `tf.keras.layers.experimental.preprocessing.PreprocessingLayer.adapt`.
|
|      `adapt()` is meant only as a single machine utility to compute layer
|      state.  To analyze a dataset that cannot fit on a single machine, see
|      [Tensorflow Transform](
|      https://www.tensorflow.org/tfx/transform/get_started) for a
|      multi-machine, map-reduce solution.
|
|      Arguments:
|        data: The data to train on. It can be passed either as a
|            `tf.data.Dataset`, or as a numpy array.
|        batch_size: Integer or `None`.
|            Number of samples per state update.
|            If unspecified, `batch_size` will default to 32.
|            Do not specify the `batch_size` if your data is in the
|            form of datasets, generators, or `keras.utils.Sequence` instances
|            (since they generate batches).
|        steps: Integer or `None`.
|            Total number of steps (batches of samples)
|            When training with input tensors such as
|            TensorFlow data tensors, the default `None` is equal to
|            the number of samples in your dataset divided by
|            the batch size, or 1 if that cannot be determined. If x is a
|            `tf.data` dataset, and 'steps' is None, the epoch will run until
|            the input dataset is exhausted. When passing an infinitely
|            repeating dataset, you must specify the `steps` argument. This
|            argument is not supported with array inputs.
|
|  get_config(self)
|      Returns the config of the layer.
|
|      A layer config is a Python dictionary (serializable)
|      containing the configuration of a layer.
|      The same layer can be reinstantiated later
|      (without its trained weights) from this configuration.
|
|      The config of a layer does not include connectivity
|      information, nor the layer class name. These are handled
|      by `Network` (one layer of abstraction above).
|
|      Note that `get_config()` does not guarantee to return a fresh copy of
|      dict every time it is called. The callers should make a copy of the
|      returned dict if they want to modify it.
|
|      Returns:
|          Python dictionary.
|
|  ----------------------------------------------------------------------
|  Data and other attributes defined here:
|
|  __abstractmethods__ = frozenset()
|
|  ----------------------------------------------------------------------
|  Methods inherited from keras.layers.preprocessing.index_lookup.IndexLookup:
|
|  call(self, inputs)
|      This is where the layer's logic lives.
|
|      The `call()` method may not create state (except in its first
|      invocation, wrapping the creation of variables or other resources in
|      `tf.init_scope()`).  It is recommended to create state in `__init__()`,
|      or the `build()` method that is called automatically before `call()`
|      executes the first time.
|
|      Args:
|        inputs: Input tensor, or dict/list/tuple of input tensors.
|          The first positional `inputs` argument is subject to special rules:
|          - `inputs` must be explicitly passed. A layer cannot have zero
|            arguments, and `inputs` cannot be provided via the default value
|            of a keyword argument.
|          - NumPy array or Python scalar values in `inputs` get cast as
|            tensors.
|          - Keras mask metadata is only collected from `inputs`.
|          - Layers are built (`build(input_shape)` method)
|            using shape info from `inputs` only.
|          - `input_spec` compatibility is only checked against `inputs`.
|          - Mixed precision input casting is only applied to `inputs`.
|            If a layer has tensor arguments in `*args` or `**kwargs`, their
|            casting behavior in mixed precision should be handled manually.
|          - The SavedModel input specification is generated using `inputs`
|            only.
|          - Integration with various ecosystem packages like TFMOT, TFLite,
|            TF.js, etc is only supported for `inputs` and not for tensors in
|            positional and keyword arguments.
|        *args: Additional positional arguments. May contain tensors, although
|          this is not recommended, for the reasons above.
|        **kwargs: Additional keyword arguments. May contain tensors, although
|          this is not recommended, for the reasons above.
|          The following optional keyword arguments are reserved:
|          - `training`: Boolean scalar tensor of Python boolean indicating
|            whether the `call` is meant for training or inference.
|          - `mask`: Boolean input mask. If the layer's `call()` method takes a
|            `mask` argument, its default value will be set to the mask
|            generated for `inputs` by the previous layer (if `input` did come
|            from a layer that generated a corresponding mask, i.e. if it came
|            from a Keras layer with masking support).
|
|      Returns:
|        A tensor or list/tuple of tensors.
|
|  compute_output_shape(self, input_shape)
|      Computes the output shape of the layer.
|
|      This method will cause the layer's state to be built, if that has not
|      happened before. This requires that the layer will later be used with
|      inputs that match the input shape provided here.
|
|      Args:
|          input_shape: Shape tuple (tuple of integers)
|              or list of shape tuples (one per output tensor of the layer).
|              Shape tuples can include None for free dimensions,
|              instead of an integer.
|
|      Returns:
|          An input shape tuple.
|
|  compute_output_signature(self, input_spec)
|      Compute the output tensor signature of the layer based on the inputs.
|
|      Unlike a TensorShape object, a TensorSpec object contains both shape
|      and dtype information for a tensor. This method allows layers to provide
|      output dtype information if it is different from the input dtype.
|      For any layer that doesn't implement this function,
|      the framework will fall back to use `compute_output_shape`, and will
|      assume that the output dtype matches the input dtype.
|
|      Args:
|        input_signature: Single TensorSpec or nested structure of TensorSpec
|          objects, describing a candidate input for the layer.
|
|      Returns:
|        Single TensorSpec or nested structure of TensorSpec objects,
|          describing how the layer would transform the provided input.
|
|      Raises:
|        TypeError: If input_signature contains a non-TensorSpec object.
|
|  finalize_state(self)
|      Finalize the statistics for the preprocessing layer.
|
|      This method is called at the end of `adapt` or after restoring a
|      serialized preprocessing layer's state. This method handles any one-time
|      operations that should occur on the layer's state before
|      `Layer.__call__`.
|
|  get_vocabulary(self, include_special_tokens=True)
|      Returns the current vocabulary of the layer.
|
|      Args:
|        include_special_tokens: If True, the returned vocabulary will include
|          mask and OOV tokens, and a term's index in the vocabulary will equal
|          the term's index when calling the layer. If False, the returned
|          vocabulary will not include any mask or OOV tokens.
|
|  reset_state(self)
|      Resets the statistics of the preprocessing layer.
|
|  set_vocabulary(self, vocabulary, idf_weights=None)
|      Sets vocabulary (and optionally document frequency) data for this layer.
|
|      This method sets the vocabulary and idf weights for this layer directly,
|      instead of analyzing a dataset through `adapt`. It should be used
|      whenever the vocab (and optionally document frequency) information is
|      already known.  If vocabulary data is already present in the layer, this
|      method will replace it.
|
|      Args:
|        vocabulary: Either an array or a string path to a text file. If
|          passing an array, can pass a tuple, list, 1D numpy array, or 1D
|          tensor containing the vocbulary terms. If passing a file path, the
|          file should contain one line per term in the vocabulary.
|        idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse
|          document frequency weights with equal length to vocabulary. Must be
|          set if `output_mode` is `"tf_idf"`. Should not be set otherwise.
|
|      Raises:
|        ValueError: If there are too many inputs, the inputs do not match, or
|          input data is missing.
|        RuntimeError: If the vocabulary cannot be set when this function is
|          called. This happens when `"multi_hot"`, `"count"`, and `"tf_idf"`
|          modes, if `pad_to_max_tokens` is False and the layer itself has
|          already been called.
|        RuntimeError: If a tensor vocabulary is passed outside of eager
|          execution.
|
|  update_state(self, data)
|      Accumulates statistics for the preprocessing layer.
|
|      Arguments:
|        data: A mini-batch of inputs to the layer.
|
|  vocab_size(self)
|
|  vocabulary_size(self)
|      Gets the current size of the layer's vocabulary.
|
|      Returns:
|        The integer size of the vocabulary, including optional mask and oov
|        indices.
|
|  ----------------------------------------------------------------------
|  Methods inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:
|
|  compile(self, run_eagerly=None, steps_per_execution=None)
|      Configures the layer for `adapt`.
|
|      Arguments:
|        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s
|          logic will not be wrapped in a `tf.function`. Recommended to leave
|          this as `None` unless your `Model` cannot be run inside a
|          `tf.function`.
|        steps_per_execution: Int. Defaults to 1. The number of batches to run
|          during each `tf.function` call. Running multiple batches inside a
|          single `tf.function` call can greatly improve performance on TPUs or
|          small models with a large Python overhead.
|
|  make_adapt_function(self)
|      Creates a function to execute one step of `adapt`.
|
|      This method can be overridden to support custom adapt logic.
|      This method is called by `PreprocessingLayer.adapt`.
|
|      Typically, this method directly controls `tf.function` settings,
|      and delegates the actual state update logic to
|      `PreprocessingLayer.update_state`.
|
|      This function is cached the first time `PreprocessingLayer.adapt`
|      is called. The cache is cleared whenever `PreprocessingLayer.compile`
|      is called.
|
|      Returns:
|        Function. The function created by this method should accept a
|        `tf.data.Iterator`, retrieve a batch, and update the state of the
|        layer.
|
|  ----------------------------------------------------------------------
|  Readonly properties inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:
|
|  is_adapted
|      Whether the layer has been fit to data already.
|
|  ----------------------------------------------------------------------
|  Methods inherited from keras.engine.base_layer.Layer:
|
|  __call__(self, *args, **kwargs)
|      Wraps `call`, applying pre- and post-processing steps.
|
|      Args:
|        *args: Positional arguments to be passed to `self.call`.
|        **kwargs: Keyword arguments to be passed to `self.call`.
|
|      Returns:
|        Output tensor(s).
|
|      Note:
|        - The following optional keyword arguments are reserved for specific
|          uses:
|          * `training`: Boolean scalar tensor of Python boolean indicating
|            whether the `call` is meant for training or inference.
|          * `mask`: Boolean input mask.
|        - If the layer's `call` method takes a `mask` argument (as some Keras
|          layers do), its default value will be set to the mask generated
|          for `inputs` by the previous layer (if `input` did come from
|          a layer that generated a corresponding mask, i.e. if it came from
|          a Keras layer with masking support.
|        - If the layer is not built, the method will call `build`.
|
|      Raises:
|        ValueError: if the layer's `call` method returns None (an invalid
|          value).
|        RuntimeError: if `super().__init__()` was not called in the
|          constructor.
|
|  __delattr__(self, name)
|      Implement delattr(self, name).
|
|  __getstate__(self)
|
|  __setattr__(self, name, value)
|      Support self.foo = trackable syntax.
|
|  __setstate__(self, state)
|
|  add_loss(self, losses, **kwargs)
|      Add loss tensor(s), potentially dependent on layer inputs.
|
|      Some losses (for instance, activity regularization losses) may be
|      dependent on the inputs passed when calling a layer. Hence, when reusing
|      the same layer on different inputs `a` and `b`, some entries in
|      `layer.losses` may be dependent on `a` and some on `b`. This method
|      automatically keeps track of dependencies.
|
|      This method can be used inside a subclassed layer or model's `call`
|      function, in which case `losses` should be a Tensor or list of Tensors.
|
|      Example:
|
|      ```python
|      class MyLayer(tf.keras.layers.Layer):
|        def call(self, inputs):
|          self.add_loss(tf.abs(tf.reduce_mean(inputs)))
|          return inputs
|      ```
|
|      This method can also be called directly on a Functional Model during
|      construction. In this case, any loss Tensors passed to this Model must
|      be symbolic and be able to be traced back to the model's `Input`s. These
|      losses become part of the model's topology and are tracked in
|      `get_config`.
|
|      Example:
|
|      ```python
|      inputs = tf.keras.Input(shape=(10,))
|      x = tf.keras.layers.Dense(10)(inputs)
|      outputs = tf.keras.layers.Dense(1)(x)
|      model = tf.keras.Model(inputs, outputs)
|      # Activity regularization.
|      model.add_loss(tf.abs(tf.reduce_mean(x)))
|      ```
|
|      If this is not the case for your loss (if, for example, your loss
|      references a `Variable` of one of the model's layers), you can wrap your
|      loss in a zero-argument lambda. These losses are not tracked as part of
|      the model's topology since they can't be serialized.
|
|      Example:
|
|      ```python
|      inputs = tf.keras.Input(shape=(10,))
|      d = tf.keras.layers.Dense(10)
|      x = d(inputs)
|      outputs = tf.keras.layers.Dense(1)(x)
|      model = tf.keras.Model(inputs, outputs)
|      # Weight regularization.
|      model.add_loss(lambda: tf.reduce_mean(d.kernel))
|      ```
|
|      Args:
|        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,
|          losses may also be zero-argument callables which create a loss
|          tensor.
|        **kwargs: Used for backwards compatibility only.
|
|  add_metric(self, value, name=None, **kwargs)
|      Adds metric tensor to the layer.
|
|      This method can be used inside the `call()` method of a subclassed layer
|      or model.
|
|      ```python
|      class MyMetricLayer(tf.keras.layers.Layer):
|        def __init__(self):
|          super(MyMetricLayer, self).__init__(name='my_metric_layer')
|          self.mean = tf.keras.metrics.Mean(name='metric_1')
|
|        def call(self, inputs):
|          self.add_metric(self.mean(inputs))
|          self.add_metric(tf.reduce_sum(inputs), name='metric_2')
|          return inputs
|      ```
|
|      This method can also be called directly on a Functional Model during
|      construction. In this case, any tensor passed to this Model must
|      be symbolic and be able to be traced back to the model's `Input`s. These
|      metrics become part of the model's topology and are tracked when you
|      save the model via `save()`.
|
|      ```python
|      inputs = tf.keras.Input(shape=(10,))
|      x = tf.keras.layers.Dense(10)(inputs)
|      outputs = tf.keras.layers.Dense(1)(x)
|      model = tf.keras.Model(inputs, outputs)
|      model.add_metric(math_ops.reduce_sum(x), name='metric_1')
|      ```
|
|      Note: Calling `add_metric()` with the result of a metric object on a
|      Functional Model, as shown in the example below, is not supported. This
|      is because we cannot trace the metric result tensor back to the model's
|      inputs.
|
|      ```python
|      inputs = tf.keras.Input(shape=(10,))
|      x = tf.keras.layers.Dense(10)(inputs)
|      outputs = tf.keras.layers.Dense(1)(x)
|      model = tf.keras.Model(inputs, outputs)
|      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')
|      ```
|
|      Args:
|        value: Metric tensor.
|        name: String metric name.
|        **kwargs: Additional keyword arguments for backward compatibility.
|          Accepted values:
|          `aggregation` - When the `value` tensor provided is not the result
|          of calling a `keras.Metric` instance, it will be aggregated by
|          default using a `keras.Metric.Mean`.
|
|  add_update(self, updates)
|      Add update op(s), potentially dependent on layer inputs.
|
|      Weight updates (for instance, the updates of the moving mean and
|      variance in a BatchNormalization layer) may be dependent on the inputs
|      passed when calling a layer. Hence, when reusing the same layer on
|      different inputs `a` and `b`, some entries in `layer.updates` may be
|      dependent on `a` and some on `b`. This method automatically keeps track
|      of dependencies.
|
|      This call is ignored when eager execution is enabled (in that case,
|      variable updates are run on the fly and thus do not need to be tracked
|      for later execution).
|
|      Args:
|        updates: Update op, or list/tuple of update ops, or zero-arg callable
|          that returns an update op. A zero-arg callable should be passed in
|          order to disable running the updates by setting `trainable=False`
|          on this Layer, when executing in Eager mode.
|
|  add_variable(self, *args, **kwargs)
|      Deprecated, do NOT use! Alias for `add_weight`.
|
|  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)
|      Adds a new variable to the layer.
|
|      Args:
|        name: Variable name.
|        shape: Variable shape. Defaults to scalar if unspecified.
|        dtype: The type of the variable. Defaults to `self.dtype`.
|        initializer: Initializer instance (callable).
|        regularizer: Regularizer instance (callable).
|        trainable: Boolean, whether the variable should be part of the layer's
|          "trainable_variables" (e.g. variables, biases)
|          or "non_trainable_variables" (e.g. BatchNorm mean and variance).
|          Note that `trainable` cannot be `True` if `synchronization`
|          is set to `ON_READ`.
|        constraint: Constraint instance (callable).
|        use_resource: Whether to use a `ResourceVariable` or not.
|          See [this guide](
|          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)
|          for more information.
|        synchronization: Indicates when a distributed a variable will be
|          aggregated. Accepted values are constants defined in the class
|          `tf.VariableSynchronization`. By default the synchronization is set
|          to `AUTO` and the current `DistributionStrategy` chooses when to
|          synchronize. If `synchronization` is set to `ON_READ`, `trainable`
|          must not be set to `True`.
|        aggregation: Indicates how a distributed variable will be aggregated.
|          Accepted values are constants defined in the class
|          `tf.VariableAggregation`.
|        **kwargs: Additional keyword arguments. Accepted values are `getter`,
|          `collections`, `experimental_autocast` and `caching_device`.
|
|      Returns:
|        The variable created.
|
|      Raises:
|        ValueError: When giving unsupported dtype and no initializer or when
|          trainable has been set to True with synchronization set as
|          `ON_READ`.
|
|  build(self, input_shape)
|      Creates the variables of the layer (optional, for subclass implementers).
|
|      This is a method that implementers of subclasses of `Layer` or `Model`
|      can override if they need a state-creation step in-between
|      layer instantiation and layer call. It is invoked automatically before
|      the first execution of `call()`.
|
|      This is typically used to create the weights of `Layer` subclasses
|      (at the discretion of the subclass implementer).
|
|      Args:
|        input_shape: Instance of `TensorShape`, or list of instances of
|          `TensorShape` if the layer expects a list of inputs
|          (one instance per input).
|
|  compute_mask(self, inputs, mask=None)
|      Computes an output mask tensor.
|
|      Args:
|          inputs: Tensor or list of tensors.
|          mask: Tensor or list of tensors.
|
|      Returns:
|          None or a tensor (or list of tensors,
|              one per output tensor of the layer).
|
|  count_params(self)
|      Count the total number of scalars composing the weights.
|
|      Returns:
|          An integer count.
|
|      Raises:
|          ValueError: if the layer isn't yet built
|            (in which case its weights aren't yet defined).
|
|  get_input_at(self, node_index)
|      Retrieves the input tensor(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first input node of the layer.
|
|      Returns:
|          A tensor (or list of tensors if the layer has multiple inputs).
|
|      Raises:
|        RuntimeError: If called in Eager mode.
|
|  get_input_mask_at(self, node_index)
|      Retrieves the input mask tensor(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first time the layer was called.
|
|      Returns:
|          A mask tensor
|          (or list of tensors if the layer has multiple inputs).
|
|  get_input_shape_at(self, node_index)
|      Retrieves the input shape(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first time the layer was called.
|
|      Returns:
|          A shape tuple
|          (or list of shape tuples if the layer has multiple inputs).
|
|      Raises:
|        RuntimeError: If called in Eager mode.
|
|  get_output_at(self, node_index)
|      Retrieves the output tensor(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first output node of the layer.
|
|      Returns:
|          A tensor (or list of tensors if the layer has multiple outputs).
|
|      Raises:
|        RuntimeError: If called in Eager mode.
|
|  get_output_mask_at(self, node_index)
|      Retrieves the output mask tensor(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first time the layer was called.
|
|      Returns:
|          A mask tensor
|          (or list of tensors if the layer has multiple outputs).
|
|  get_output_shape_at(self, node_index)
|      Retrieves the output shape(s) of a layer at a given node.
|
|      Args:
|          node_index: Integer, index of the node
|              from which to retrieve the attribute.
|              E.g. `node_index=0` will correspond to the
|              first time the layer was called.
|
|      Returns:
|          A shape tuple
|          (or list of shape tuples if the layer has multiple outputs).
|
|      Raises:
|        RuntimeError: If called in Eager mode.
|
|  get_weights(self)
|      Returns the current weights of the layer, as NumPy arrays.
|
|      The weights of a layer represent the state of the layer. This function
|      returns both trainable and non-trainable weight values associated with
|      this layer as a list of NumPy arrays, which can in turn be used to load
|      state into similarly parameterized layers.
|
|      For example, a `Dense` layer returns a list of two values: the kernel
|      matrix and the bias vector. These can be used to set the weights of
|      another `Dense` layer:
|
|      >>> layer_a = tf.keras.layers.Dense(1,
|      ...   kernel_initializer=tf.constant_initializer(1.))
|      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
|      >>> layer_a.get_weights()
|      [array([[1.],
|             [1.],
|             [1.]], dtype=float32), array([0.], dtype=float32)]
|      >>> layer_b = tf.keras.layers.Dense(1,
|      ...   kernel_initializer=tf.constant_initializer(2.))
|      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
|      >>> layer_b.get_weights()
|      [array([[2.],
|             [2.],
|             [2.]], dtype=float32), array([0.], dtype=float32)]
|      >>> layer_b.set_weights(layer_a.get_weights())
|      >>> layer_b.get_weights()
|      [array([[1.],
|             [1.],
|             [1.]], dtype=float32), array([0.], dtype=float32)]
|
|      Returns:
|          Weights values as a list of NumPy arrays.
|
|  set_weights(self, weights)
|      Sets the weights of the layer, from NumPy arrays.
|
|      The weights of a layer represent the state of the layer. This function
|      sets the weight values from numpy arrays. The weight values should be
|      passed in the order they are created by the layer. Note that the layer's
|      weights must be instantiated before calling this function, by calling
|      the layer.
|
|      For example, a `Dense` layer returns a list of two values: the kernel
|      matrix and the bias vector. These can be used to set the weights of
|      another `Dense` layer:
|
|      >>> layer_a = tf.keras.layers.Dense(1,
|      ...   kernel_initializer=tf.constant_initializer(1.))
|      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
|      >>> layer_a.get_weights()
|      [array([[1.],
|             [1.],
|             [1.]], dtype=float32), array([0.], dtype=float32)]
|      >>> layer_b = tf.keras.layers.Dense(1,
|      ...   kernel_initializer=tf.constant_initializer(2.))
|      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
|      >>> layer_b.get_weights()
|      [array([[2.],
|             [2.],
|             [2.]], dtype=float32), array([0.], dtype=float32)]
|      >>> layer_b.set_weights(layer_a.get_weights())
|      >>> layer_b.get_weights()
|      [array([[1.],
|             [1.],
|             [1.]], dtype=float32), array([0.], dtype=float32)]
|
|      Args:
|        weights: a list of NumPy arrays. The number
|          of arrays and their shape must match
|          number of the dimensions of the weights
|          of the layer (i.e. it should match the
|          output of `get_weights`).
|
|      Raises:
|        ValueError: If the provided weights list does not match the
|          layer's specifications.
|
|  ----------------------------------------------------------------------
|  Class methods inherited from keras.engine.base_layer.Layer:
|
|  from_config(config) from abc.ABCMeta
|      Creates a layer from its config.
|
|      This method is the reverse of `get_config`,
|      capable of instantiating the same layer from the config
|      dictionary. It does not handle layer connectivity
|      (handled by Network), nor weights (handled by `set_weights`).
|
|      Args:
|          config: A Python dictionary, typically the
|              output of get_config.
|
|      Returns:
|          A layer instance.
|
|  ----------------------------------------------------------------------
|  Readonly properties inherited from keras.engine.base_layer.Layer:
|
|  compute_dtype
|      The dtype of the layer's computations.
|
|      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless
|      mixed precision is used, this is the same as `Layer.dtype`, the dtype of
|      the weights.
|
|      Layers automatically cast their inputs to the compute dtype, which
|      causes computations and the output to be in the compute dtype as well.
|      This is done by the base Layer class in `Layer.__call__`, so you do not
|      have to insert these casts if implementing your own layer.
|
|      Layers often perform certain internal computations in higher precision
|      when `compute_dtype` is float16 or bfloat16 for numeric stability. The
|      output will still typically be float16 or bfloat16 in such cases.
|
|      Returns:
|        The layer's compute dtype.
|
|  dtype
|      The dtype of the layer weights.
|
|      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless
|      mixed precision is used, this is the same as `Layer.compute_dtype`, the
|      dtype of the layer's computations.
|
|  dtype_policy
|      The dtype policy associated with this layer.
|
|      This is an instance of a `tf.keras.mixed_precision.Policy`.
|
|  dynamic
|      Whether the layer is dynamic (eager-only); set in the constructor.
|
|  inbound_nodes
|      Return Functional API nodes upstream of this layer.
|
|  input
|      Retrieves the input tensor(s) of a layer.
|
|      Only applicable if the layer has exactly one input,
|      i.e. if it is connected to one incoming layer.
|
|      Returns:
|          Input tensor or list of input tensors.
|
|      Raises:
|        RuntimeError: If called in Eager mode.
|        AttributeError: If no inbound nodes are found.
|
|  input_mask
|      Retrieves the input mask tensor(s) of a layer.
|
|      Only applicable if the layer has exactly one inbound node,
|      i.e. if it is connected to one incoming layer.
|
|      Returns:
|          Input mask tensor (potentially None) or list of input
|          mask tensors.
|
|      Raises:
|          AttributeError: if the layer is connected to
|          more than one incoming layers.
|
|  input_shape
|      Retrieves the input shape(s) of a layer.
|
|      Only applicable if the layer has exactly one input,
|      i.e. if it is connected to one incoming layer, or if all inputs
|      have the same shape.
|
|      Returns:
|          Input shape, as an integer shape tuple
|          (or list of shape tuples, one tuple per input tensor).
|
|      Raises:
|          AttributeError: if the layer has no defined input_shape.
|          RuntimeError: if called in Eager mode.
|
|  losses
|      List of losses added using the `add_loss()` API.
|
|      Variable regularization tensors are created when this property is
|      accessed, so it is eager safe: accessing `losses` under a
|      `tf.GradientTape` will propagate gradients back to the corresponding
|      variables.
|
|      Examples:
|
|      >>> class MyLayer(tf.keras.layers.Layer):
|      ...   def call(self, inputs):
|      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))
|      ...     return inputs
|      >>> l = MyLayer()
|      >>> l(np.ones((10, 1)))
|      >>> l.losses
|      [1.0]
|
|      >>> inputs = tf.keras.Input(shape=(10,))
|      >>> x = tf.keras.layers.Dense(10)(inputs)
|      >>> outputs = tf.keras.layers.Dense(1)(x)
|      >>> model = tf.keras.Model(inputs, outputs)
|      >>> # Activity regularization.
|      >>> len(model.losses)
|      0
|      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))
|      >>> len(model.losses)
|      1
|
|      >>> inputs = tf.keras.Input(shape=(10,))
|      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')
|      >>> x = d(inputs)
|      >>> outputs = tf.keras.layers.Dense(1)(x)
|      >>> model = tf.keras.Model(inputs, outputs)
|      >>> # Weight regularization.
|      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))
|      >>> model.losses
|      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]
|
|      Returns:
|        A list of tensors.
|
|  metrics
|      List of metrics added using the `add_metric()` API.
|
|      Example:
|
|      >>> input = tf.keras.layers.Input(shape=(3,))
|      >>> d = tf.keras.layers.Dense(2)
|      >>> output = d(input)
|      >>> d.add_metric(tf.reduce_max(output), name='max')
|      >>> d.add_metric(tf.reduce_min(output), name='min')
|      >>> [m.name for m in d.metrics]
|      ['max', 'min']
|
|      Returns:
|        A list of `Metric` objects.
|
|  name
|      Name of the layer (string), set in the constructor.
|
|  non_trainable_variables
|      Sequence of non-trainable variables owned by this module and its submodules.
|
|      Note: this method uses reflection to find variables on the current instance
|      and submodules. For performance reasons you may wish to cache the result
|      of calling this method if you don't expect the return value to change.
|
|      Returns:
|        A sequence of variables for the current module (sorted by attribute
|        name) followed by variables from all submodules recursively (breadth
|        first).
|
|  non_trainable_weights
|      List of all non-trainable weights tracked by this layer.
|
|      Non-trainable weights are *not* updated during training. They are
|      expected to be updated manually in `call()`.
|
|      Returns:
|        A list of non-trainable variables.
|
|  outbound_nodes
|      Return Functional API nodes downstream of this layer.
|
|  output
|      Retrieves the output tensor(s) of a layer.
|
|      Only applicable if the layer has exactly one output,
|      i.e. if it is connected to one incoming layer.
|
|      Returns:
|        Output tensor or list of output tensors.
|
|      Raises:
|        AttributeError: if the layer is connected to more than one incoming
|          layers.
|        RuntimeError: if called in Eager mode.
|
|  output_mask
|      Retrieves the output mask tensor(s) of a layer.
|
|      Only applicable if the layer has exactly one inbound node,
|      i.e. if it is connected to one incoming layer.
|
|      Returns:
|          Output mask tensor (potentially None) or list of output
|          mask tensors.
|
|      Raises:
|          AttributeError: if the layer is connected to
|          more than one incoming layers.
|
|  output_shape
|      Retrieves the output shape(s) of a layer.
|
|      Only applicable if the layer has one output,
|      or if all outputs have the same shape.
|
|      Returns:
|          Output shape, as an integer shape tuple
|          (or list of shape tuples, one tuple per output tensor).
|
|      Raises:
|          AttributeError: if the layer has no defined output shape.
|          RuntimeError: if called in Eager mode.
|
|  trainable_variables
|      Sequence of trainable variables owned by this module and its submodules.
|
|      Note: this method uses reflection to find variables on the current instance
|      and submodules. For performance reasons you may wish to cache the result
|      of calling this method if you don't expect the return value to change.
|
|      Returns:
|        A sequence of variables for the current module (sorted by attribute
|        name) followed by variables from all submodules recursively (breadth
|        first).
|
|  trainable_weights
|      List of all trainable weights tracked by this layer.
|
|      Trainable weights are updated via gradient descent during training.
|
|      Returns:
|        A list of trainable variables.
|
|  updates
|
|  variable_dtype
|      Alias of `Layer.dtype`, the dtype of the weights.
|
|  variables
|      Returns the list of all layer variables/weights.
|
|      Alias of `self.weights`.
|
|      Note: This will not track the weights of nested `tf.Modules` that are
|      not themselves Keras layers.
|
|      Returns:
|        A list of variables.
|
|  weights
|      Returns the list of all layer variables/weights.
|
|      Returns:
|        A list of variables.
|
|  ----------------------------------------------------------------------
|  Data descriptors inherited from keras.engine.base_layer.Layer:
|
|  activity_regularizer
|      Optional regularizer function for the output of this layer.
|
|  input_spec
|      `InputSpec` instance(s) describing the input format for this layer.
|
|      When you create a layer subclass, you can set `self.input_spec` to
|      enable the layer to run input compatibility checks when it is called.
|      Consider a `Conv2D` layer: it can only be called on a single input
|      tensor of rank 4. As such, you can set, in `__init__()`:
|
|      ```python
|      self.input_spec = tf.keras.layers.InputSpec(ndim=4)
|      ```
|
|      Now, if you try to call the layer on an input that isn't rank 4
|      (for instance, an input of shape `(2,)`, it will raise a
|      nicely-formatted error:
|
|      ```
|      ValueError: Input 0 of layer conv2d is incompatible with the layer:
|      expected ndim=4, found ndim=1. Full shape received: [2]
|      ```
|
|      Input checks that can be specified via `input_spec` include:
|      - Structure (e.g. a single input, a list of 2 inputs, etc)
|      - Shape
|      - Rank (ndim)
|      - Dtype
|
|      For more information, see `tf.keras.layers.InputSpec`.
|
|      Returns:
|        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.
|
|  stateful
|
|  supports_masking
|      Whether this layer supports computing a mask using `compute_mask`.
|
|  trainable
|
|  ----------------------------------------------------------------------
|  Class methods inherited from tensorflow.python.module.module.Module:
|
|  with_name_scope(method) from abc.ABCMeta
|      Decorator to automatically enter the module name scope.
|
|      >>> class MyModule(tf.Module):
|      ...   @tf.Module.with_name_scope
|      ...   def __call__(self, x):
|      ...     if not hasattr(self, 'w'):
|      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
|      ...     return tf.matmul(x, self.w)
|
|      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose
|      names included the module name:
|
|      >>> mod = MyModule()
|      >>> mod(tf.ones([1, 2]))
|      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
|      >>> mod.w
|      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
|      numpy=..., dtype=float32)>
|
|      Args:
|        method: The method to wrap.
|
|      Returns:
|        The original method wrapped such that it enters the module's name scope.
|
|  ----------------------------------------------------------------------
|  Readonly properties inherited from tensorflow.python.module.module.Module:
|
|  name_scope
|      Returns a `tf.name_scope` instance for this class.
|
|  submodules
|      Sequence of all sub-modules.
|
|      Submodules are modules which are properties of this module, or found as
|      properties of modules which are properties of this module (and so on).
|
|      >>> a = tf.Module()
|      >>> b = tf.Module()
|      >>> c = tf.Module()
|      >>> a.b = b
|      >>> b.c = c
|      >>> list(a.submodules) == [b, c]
|      True
|      >>> list(b.submodules) == [c]
|      True
|      >>> list(c.submodules) == []
|      True
|
|      Returns:
|        A sequence of all submodules.
|
|  ----------------------------------------------------------------------
|  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:
|
|  __dict__
|      dictionary for instance variables (if defined)
|
|  __weakref__
|      list of weak references to the object (if defined)
|
|  ----------------------------------------------------------------------
|  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:
|
|  __new__(cls, *args, **kwargs)
|      Create and return a new object.  See help(type) for accurate signature.
